input {

    file {
        id => "gatling_file_input"
        path => ["/var/tmp/logstash/input/*.log"]
        start_position => "beginning"
    }

}

filter {

    # REQUEST\t(?<scenario_name>[^\t]*)\t%{NUMBER:user_id}\t(?<group_name>[^\t]*)\t(?<request_name>[^\t]*)\t(?<start_timestamp>[^\t]*)\t(?<end_timestamp>[^\t]*)\t(?<status>[^\t]*)\t(?<error_message>[^\t]*)\t(?<correlation_id>[^\t]*)
    # REQUEST\t%{FIELD:scenario_name}\t%{FIELD:user_id:int}\t%{FIELD:group_name}\t%{FIELD:request_name}\t%{FIELD:start_timestamp:int}\t%{FIELD:end_timestamp:int}\t%{FIELD:status}\t%{FIELD:error_message}\t%{FIELD:correlation_id}

    grok {
        id => "gatling_grok"
        pattern_definitions => {
            "FIELD" => "[^\t]*"
        }
        match => {
            "message" => "REQUEST\t%{FIELD:scenario_name}\t%{FIELD:user_id:int}\t%{FIELD:group_name}\t%{FIELD:request_name}\t%{FIELD:start_timestamp:int}\t%{FIELD:end_timestamp:int}\t%{FIELD:status}\t%{FIELD:error_message}\t%{FIELD:correlation_id}"
        }
        add_field => {
            "type" => "gatling_request"
        }
        remove_field => ["message"]
    }

    date {
        id => "gatling_start_date"
        match => ["start_timestamp", "UNIX_MS"]
        target => "@timestamp"
    }

    date {
        id => "gatling_end_date"
        match => ["end_timestamp", "UNIX_MS"]
        target => "end_date"
    }

    if [start_timestamp] and [end_timestamp] {
        ruby {
            id => "gatling_request_duration"
            code => "event.set('duration_ms', event.get('end_timestamp') - event.get('start_timestamp'))"
        }
    }

}

output {

    stdout {
        codec => rubydebug
    }

    if [type] == "gatling_request" {
        elasticsearch {
            hosts => ["http://elasticsearch:9200"]
            user => "logstash_writer"
            password => "password"
            http_compression => true
        }
    }

}
